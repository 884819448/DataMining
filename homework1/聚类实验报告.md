# 图像数据集聚类实验报告

## 实验概述

本实验针对课程提供的工业图像数据集（共 6 个类别、600 张图片）完成**无监督聚类**任务：

- **输入**：`../Cluster/dataset/` 下的所有图片（不使用标签参与聚类）
- **输出**：每张图片对应的聚类编号 `cluster_id`（共 6 簇）
- **离线评估**：读取 `../Cluster/cluster_labels.json` 仅用于计算 ARI/NMI/映射后 Accuracy，并生成可视化与对比报告

本作业的实现分为两个脚本（与你的代码一致）：

- **聚类主程序**：`clustring.py`
  - 负责：读取图片 -> ResNet50 提特征 -> PCA 降维 -> K-Means 聚类 -> 保存 `clustering_results.json`
- **对比评估与可视化**：`compare_results.py`
  - 负责：根据标准答案做簇-类映射、计算指标、保存 `comparison_report.json`，并生成 `clustering_visualization.png` / `confusion_matrix.png`

因此，报告中的“效果评估/可视化”均属于**离线分析**部分，不会反向影响聚类过程。

## 1.0 问题的形式化描述 (5%)

### 问题定义

给定包含 600 张图像的数据集 $D = \{x_1, x_2, ..., x_{600}\}$，每张图像属于 6 个类别之一（bottle、cable、leather、pill、tile、transistor）。目标是在**不使用标签信息**的情况下，将图像划分为 $k=6$ 个聚类，使得：

- **簇内相似度最大化**：同一聚类内的图像尽可能相似
- **簇间相似度最小化**：不同聚类之间的图像尽可能不同

### 数据与输出形式

本实验的程序读取如下路径的数据与标签：

- 数据集目录：`../Cluster/dataset/`（相对 `homework1/`）
- 标准标签文件：`../Cluster/cluster_labels.json`（用于离线评估，不参与训练/聚类）

聚类完成后输出：

- 聚类结果：`homework1/clustering_results.json`，格式为 `{"image_name": cluster_id}`
- 对比分析报告：`homework1/comparison_report.json`，包含 ARI/NMI/Accuracy、簇-类别映射、错误样本列表
- 可视化图片：`homework1/clustering_visualization.png` 与 `homework1/confusion_matrix.png`

补充说明（与代码一致）：

- `clustring.py` 在完成聚类后会将 `{image_name: cluster_id}` 写入 `clustering_results.json`。
- `compare_results.py` 读取上述预测文件与标准答案文件，生成 `comparison_report.json`（含指标、映射与错误样本列表），并绘制两张图片。

### 数学形式化

设图像 $x_i$ 经特征提取后得到特征向量 $f_i \in \mathbb{R}^d$，聚类问题形式化为：

$$
\min_{C_1, ..., C_k} \sum_{j=1}^{k} \sum_{x_i \in C_j} \|f_i - \mu_j\|^2
$$

其中 $\mu_j = \frac{1}{|C_j|} \sum_{x_i \in C_j} f_i$ 是聚类中心，约束条件为 $C_i \cap C_j = \emptyset$ 且 $\bigcup_{j=1}^{k} C_j = D$。

### 实验流程（端到端）

从实现角度，本实验的端到端流程可以写为：

1. 读取目录下全部图片文件名，并排序（保证可复现）。
2. 使用 ImageNet 预训练 ResNet50（去掉最后分类层）逐张图片抽取 2048 维深度特征。
3. 对 2048 维特征做 PCA，将维度压缩到 50 维。
4. 在 PCA 空间用 K-Means（k=6）得到每个样本的聚类编号。
5. 保存聚类结果到 `clustering_results.json`。
6. （离线）加载 `cluster_labels.json`，计算 ARI/NMI，并基于多数投票做“簇 -> 类别”的映射，得到映射后 Accuracy；同时输出混淆矩阵与可视化图。

## 1.1 如何处理图像特征 (5%)

### 特征提取方法

采用**深度学习特征提取**，使用在 ImageNet 上预训练的 **ResNet50** 模型：

- **特征层**：移除最后的分类层，使用全局平均池化输出
- **特征维度**：2048 维向量
- **优势**：强大的语义特征提取能力，对工业图像区分度高

在代码实现中，模型构建方式为（去掉最后的全连接层 `fc`，保留到 `avgpool`）：

```python
model = models.resnet50(pretrained=True)
model = torch.nn.Sequential(*(list(model.children())[:-1]))
model.eval()
```

前向提取在 `torch.no_grad()` 下执行，避免反向传播与额外显存开销。

### 预处理流程

```python
preprocess = transforms.Compose([
    transforms.Resize(256),           # 调整尺寸
    transforms.CenterCrop(224),       # 中心裁剪
    transforms.ToTensor(),            # 转换为张量
    transforms.Normalize(             # ImageNet 标准化
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
```

### 实现细节与可复现性

- **设备选择**：程序自动选择 `cuda`（若可用）否则使用 `cpu`。
- **样本顺序**：对文件名排序 `image_files.sort()`，保证每次运行读取顺序一致。
- **异常处理**：若某张图片读取/预处理失败，会用全零向量 `np.zeros(2048)` 作为兜底特征，保证流程不中断（实际数据集正常时不会触发）。

补充说明（与实现一致）：

- **逐张推理**：当前实现按图片逐张前向推理（`for img_file in tqdm(image_files)`），便于定位单张异常样本。
- **不做数据增强**：预处理采用 `Resize + CenterCrop`，不引入随机翻转/颜色扰动等增强，保证特征稳定；增强更适合监督训练，本实验目标是获得一致的表征供聚类使用。

### 降维处理

使用 **PCA** 将 2048 维特征降至 50 维：

```python
pca = PCA(n_components=50, random_state=42)
features_pca = pca.fit_transform(features)
```

**降维原因**：
- 去除冗余和噪声
- 缓解维度灾难
- 提高聚类效率

更具体地：K-Means 默认使用欧氏距离并最小化簇内平方误差（SSE）。在高维空间中，距离度量更容易受噪声维度影响，导致簇划分不稳定。PCA 能将主要方差信息压缩到低维子空间，使得欧氏距离在该子空间更有意义，从而提升聚类鲁棒性。

说明：本实验的聚类算法在 PCA 空间中使用欧氏距离进行划分，因此 PCA 既能降维，也能在一定程度上“压缩”深度特征中的相关性，使 K-Means 更稳定。

## 1.2 选择合适的聚类算法 (10%)

### 算法对比

| 算法 | 优点 | 缺点 | 适用性 |
|------|------|------|--------|
| **K-Means** | 简单高效，易实现 | 需预设 k 值 | ✓ 适合 |
| DBSCAN | 发现任意形状簇 | 参数敏感 | ✗ 不适合 |
| 层次聚类 | 可视化树状图 | 复杂度 O(n²) | ✗ 计算量大 |

### K-Means 算法原理

**核心步骤**：
1. 随机初始化 k 个聚类中心
2. 将每个样本分配到最近的中心
3. 重新计算每个聚类的中心
4. 重复 2-3 直到收敛

**时间复杂度**：$O(n \cdot k \cdot d \cdot i)$，其中 n=600, k=6, d=50, i<100

补充说明（实现细节）：

- 本实验使用 `sklearn.cluster.KMeans`，其默认初始化方式为 **k-means++**，有助于得到更好的初始中心、提升收敛质量。
- `sklearn` 默认 `max_iter=300`，在本数据规模（600）与降维后特征（50）下迭代成本较低。

### 关键超参数设置（与代码一致）

- `n_clusters=6`：由数据集已知类别数给定。
- `random_state=42`：固定随机性，提升可复现性。
- `n_init=10`：多次初始化选取最优结果，降低落入局部最优的概率。

对应实现：

```python
kmeans = KMeans(n_clusters=6, random_state=42, n_init=10)
clusters = kmeans.fit_predict(features_pca)
```

### 选择理由

1. **数据特性**：ResNet50 特征在欧氏空间中具有良好聚类结构
2. **类别已知**：数据集有 6 个明确类别，适合 K-Means
3. **计算效率**：600 样本规模适中，快速收敛
4. **实验验证**：在本数据集上取得 ARI/NMI/Accuracy 均为 1.0（见 1.3）

### 其他算法未选用原因补充

- **DBSCAN**：需要设置 `eps` 与 `min_samples`，对“距离尺度/密度差异”敏感。深度特征的距离分布未必满足密度可分假设，且该数据集各类规模均衡（每类 100 张）并不强调噪声点检测，因此不优先考虑。
- **层次聚类**：虽然可输出树状结构便于解释，但距离矩阵计算与合并过程代价较高（O(n^2) 量级），对 600 张图片虽然可跑，但整体工程复杂度与可复现实现成本更高。

## 1.3 评估你的聚类效果 (5%)

### 评估指标

#### Adjusted Rand Index (ARI)

$$
\text{ARI} = \frac{\text{RI} - \mathbb{E}[\text{RI}]}{\max(\text{RI}) - \mathbb{E}[\text{RI}]}
$$

- 取值范围：[-1, 1]
- ARI = 1 表示完美聚类
- 调整了随机因素影响

#### Normalized Mutual Information (NMI)

$$
\text{NMI} = \frac{2 \times I(C; T)}{H(C) + H(T)}
$$

- 取值范围：[0, 1]
- 基于信息论，衡量聚类捕获真实分布的信息量

### 评估实现说明（ARI/NMI/Accuracy 的计算口径）

- **ARI/NMI**：直接用 `sklearn.metrics`，输入为 `true_label_list`（真实类别字符串）与 `pred_cluster_list`（聚类编号）。
- **Accuracy**：由于聚类编号本身无语义，需要先做“簇 -> 类别”的映射。本实验采用**多数投票**：对每个簇统计其中出现最多的真实类别，将其作为该簇的类别标签；再计算映射后的分类准确率。

映射逻辑在 `compare_results.py` 中实现：

```python
main_label = max(label_counts.items(), key=lambda x: x[1])[0]
cluster_to_label[cluster] = main_label
```

补充说明（与脚本一致）：

- 评估脚本按 `sorted(pred_clusters.keys())` 对图片名排序后构建 `true_label_list` / `pred_cluster_list`，确保列表对齐。
- `comparison_report.json` 会保存：
  - `metrics`：ARI/NMI/accuracy 及正确数
  - `cluster_mapping`：聚类编号到类别的映射
  - `errors`：映射后仍不一致的样本列表（本次为空）

### 实验结果

**评估指标**：
```
Adjusted Rand Index (ARI):           1.0000
Normalized Mutual Information (NMI): 1.0000
准确率 (Accuracy):                    1.0000 (600/600)
```

**聚类映射**：
- Cluster 0 → leather (皮革)
- Cluster 1 → bottle (瓶子)
- Cluster 2 → pill (药丸)
- Cluster 3 → transistor (晶体管)
- Cluster 4 → cable (电缆)
- Cluster 5 → tile (瓷砖)

### 可视化结果

#### 综合分析图

![聚类结果可视化](clustering_visualization.png)

**图表说明**：
- **左上：混淆矩阵** - 完美对角矩阵，无错误分类
- **中上：聚类分布** - 每个聚类 100% 纯度
- **右上：评估指标** - ARI、NMI、Accuracy 均为 1.0
- **左下：样本数量** - 每个类别均衡分布（各 100 张）
- **中下：映射关系** - 聚类编号到类别的对应表
- **右下：纯度分布** - 所有聚类纯度均为 100%

#### 混淆矩阵详细图

![混淆矩阵](confusion_matrix.png)

**结果分析**：
- 完美的对角矩阵，所有非对角元素为 0
- 每个类别的 100 张图片全部被正确分配到同一聚类
- 无任何错误分类

### 运行方式与复现步骤（与工程文件对应）

在 `homework1/` 目录下按顺序执行：

1. 运行 `clustring.py` 生成聚类结果文件 `clustering_results.json`。
2. 运行 `compare_results.py` 读取聚类结果与标准答案，生成 `comparison_report.json` 并输出两张可视化图片。

依赖包见 `requirements.txt`（核心依赖包括 `torch`、`torchvision`、`scikit-learn`、`matplotlib`、`seaborn`、`tqdm` 等）。

### 可复现性说明

- 固定 `PCA(random_state=42)` 与 `KMeans(random_state=42, n_init=10)`，并且对输入图片名排序读取，因此在相同环境下重复运行可得到一致结果。
- 如需进一步做“鲁棒性/敏感性分析”，可以在上述代码中修改 `random_state` 或 `n_components`，重复运行后比较 ARI/NMI 的波动情况。

### 局限性与改进方向（可选）

虽然本次数据集上指标达到 1.0，但该结论依赖于数据集“类别间视觉差异明显、背景/光照相对稳定”等特点。若面对更复杂的真实场景，可以考虑：

1. 更强表征：使用对比学习特征（如 SimCLR/MoCo）或更适合工业图像的预训练模型。
2. 更稳的降维/度量：尝试 `StandardScaler + PCA` 或使用余弦距离并配合球面 K-Means。
3. 选择 k 的策略：当类别数未知时，可用轮廓系数、CH 指数等无监督指标选择 k。

### 评估总结

| 评估维度 | 结果 | 说明 |
|----------|------|------|
| **ARI** | 1.0000 | 完美聚类 |
| **NMI** | 1.0000 | 完全捕获真实分布 |
| **准确率** |   100% (600/600) | 零错误 |
| **混淆矩阵** | 完美对角矩阵 | 无错误分类 |
| **可复现性** | 稳定 | 固定随机种子 + 固定读取顺序 |

---

## 总结

本实验成功实现了图像数据集的无监督聚类任务：

1. **问题形式化**：将聚类问题转化为特征空间优化问题
2. **特征工程**：ResNet50 提取深度特征 + PCA 降维
3. **算法选择**：K-Means 算法（`n_clusters=6`，`n_init=10`，`random_state=42`）
4. **完美效果**：ARI=1.0, NMI=1.0，600/600 全部正确

实验证明**深度特征 + PCA + K-Means** 对视觉差异明显的工业图像聚类非常有效。
